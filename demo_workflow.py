#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç«¯åˆ°ç«¯æ¼”ç¤ºè„šæœ¬

æ¼”ç¤ºå®Œæ•´çš„çˆ¬è™«â†’è§£æâ†’å±•ç¤ºå·¥ä½œæµç¨‹
Author: Spidermind
"""

import sys
import os
import time
import requests
import json
from datetime import datetime

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from models.base import SessionLocal
from models.crawl import CrawlTask
from models.candidate import Candidate

def print_header(title):
    """æ‰“å°æ ‡é¢˜"""
    print("\n" + "=" * 60)
    print(f"ğŸ¯ {title}")
    print("=" * 60)

def print_step(step, description):
    """æ‰“å°æ­¥éª¤"""
    print(f"\nğŸ“ æ­¥éª¤ {step}: {description}")
    print("-" * 40)

def insert_demo_tasks():
    """æ’å…¥æ¼”ç¤ºä»»åŠ¡"""
    print_step(1, "æ’å…¥æ¼”ç¤ºä»»åŠ¡åˆ°æ•°æ®åº“")
    
    db = SessionLocal()
    try:
        # GitHubæ¼”ç¤ºä»»åŠ¡
        github_tasks = [
            CrawlTask(
                source='github',
                type='profile',
                github_login='torvalds',
                status='pending'
            ),
            CrawlTask(
                source='github',
                type='profile', 
                github_login='gvanrossum',
                status='pending'
            ),
            CrawlTask(
                source='github',
                type='profile',
                github_login='yyx990803',
                status='pending'
            )
        ]
        
        # OpenReviewæ¼”ç¤ºä»»åŠ¡
        openreview_tasks = [
            CrawlTask(
                source='openreview',
                type='forum',
                url='https://openreview.net/forum?id=example1',
                status='pending'
            ),
            CrawlTask(
                source='openreview',
                type='forum',
                url='https://openreview.net/forum?id=example2', 
                status='pending'
            )
        ]
        
        # Homepageæ¼”ç¤ºä»»åŠ¡
        homepage_tasks = [
            CrawlTask(
                source='homepage',
                type='homepage',
                url='https://karpathy.ai',
                status='pending'
            ),
            CrawlTask(
                source='homepage',
                type='homepage',
                url='https://colah.github.io',
                status='pending'
            )
        ]
        
        all_tasks = github_tasks + openreview_tasks + homepage_tasks
        
        for task in all_tasks:
            db.add(task)
        
        db.commit()
        
        print(f"âœ… æˆåŠŸæ’å…¥ {len(all_tasks)} ä¸ªæ¼”ç¤ºä»»åŠ¡:")
        print(f"   ğŸ“± GitHubä»»åŠ¡: {len(github_tasks)} ä¸ª")
        print(f"   ğŸ“„ OpenReviewä»»åŠ¡: {len(openreview_tasks)} ä¸ª")
        print(f"   ğŸŒ Homepageä»»åŠ¡: {len(homepage_tasks)} ä¸ª")
        
        return len(all_tasks)
        
    except Exception as e:
        print(f"âŒ æ’å…¥ä»»åŠ¡å¤±è´¥: {e}")
        db.rollback()
        return 0
    finally:
        db.close()

def check_server_status(base_url="http://localhost:8000"):
    """æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€"""
    print_step(2, "æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€")
    
    try:
        response = requests.get(f"{base_url}/dashboard/health", timeout=10)
        if response.status_code == 200:
            health_data = response.json()
            print(f"âœ… æœåŠ¡å™¨è¿è¡Œæ­£å¸¸")
            print(f"   æ•°æ®åº“çŠ¶æ€: {health_data['data']['database_status']}")
            print(f"   ç³»ç»ŸçŠ¶æ€: {health_data['data']['system_status']}")
            return True
        else:
            print(f"âŒ æœåŠ¡å™¨å“åº”å¼‚å¸¸: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ æœåŠ¡å™¨è¿æ¥å¤±è´¥: {e}")
        print(f"è¯·ç¡®ä¿æœåŠ¡å™¨å·²å¯åŠ¨: uvicorn main:app --host 0.0.0.0 --port 8000")
        return False

def start_crawler(source, config=None, base_url="http://localhost:8000"):
    """å¯åŠ¨æŒ‡å®šçˆ¬è™«"""
    print(f"\nğŸš€ å¯åŠ¨ {source.upper()} çˆ¬è™«")
    
    if config is None:
        config = {"batch_size": 5}
    
    try:
        if source == "github":
            config.update({"recent_n": 3, "star_n": 3, "follow_depth": 1})
            
        response = requests.post(
            f"{base_url}/crawl/{source}/start",
            json=config,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"âœ… {source.upper()} çˆ¬è™«å¯åŠ¨æˆåŠŸ")
            print(f"   æ‰¹æ¬¡ID: {result.get('batch_id', 'N/A')}")
            return True
        else:
            print(f"âŒ {source.upper()} çˆ¬è™«å¯åŠ¨å¤±è´¥: {response.status_code}")
            try:
                error_detail = response.json().get('detail', 'Unknown error')
                print(f"   é”™è¯¯è¯¦æƒ…: {error_detail}")
            except:
                pass
            return False
            
    except Exception as e:
        print(f"âŒ {source.upper()} çˆ¬è™«å¯åŠ¨å¼‚å¸¸: {e}")
        return False

def monitor_crawl_progress(max_wait_minutes=10, base_url="http://localhost:8000"):
    """ç›‘æ§çˆ¬è™«è¿›åº¦"""
    print_step(3, f"ç›‘æ§çˆ¬è™«è¿›åº¦ (æœ€å¤§ç­‰å¾… {max_wait_minutes} åˆ†é’Ÿ)")
    
    start_time = time.time()
    max_wait_seconds = max_wait_minutes * 60
    
    while time.time() - start_time < max_wait_seconds:
        try:
            # è·å–ä»»åŠ¡ç»Ÿè®¡
            response = requests.get(f"{base_url}/dashboard/tasks", timeout=10)
            if response.status_code == 200:
                stats = response.json()['data']
                
                total_pending = stats['total']['pending']
                total_done = stats['total']['done'] 
                total_failed = stats['total']['failed']
                total_running = stats['total']['running']
                
                print(f"ğŸ“Š ä»»åŠ¡çŠ¶æ€: å¾…å¤„ç†={total_pending}, å·²å®Œæˆ={total_done}, å¤±è´¥={total_failed}, è¿è¡Œä¸­={total_running}")
                
                # å¦‚æœæ²¡æœ‰å¾…å¤„ç†å’Œè¿è¡Œä¸­çš„ä»»åŠ¡ï¼Œè¯´æ˜å®Œæˆäº†
                if total_pending == 0 and total_running == 0:
                    print(f"âœ… æ‰€æœ‰çˆ¬è™«ä»»åŠ¡æ‰§è¡Œå®Œæˆ!")
                    print(f"   æ€»è€—æ—¶: {time.time() - start_time:.1f} ç§’")
                    return True
                
                # æŒ‰æºæ˜¾ç¤ºè¯¦ç»†è¿›åº¦
                for source in stats['sources']:
                    source_stats = stats['by_source'][source]
                    print(f"   {source}: å¾…å¤„ç†={source_stats['by_status']['pending']}, "
                          f"å·²å®Œæˆ={source_stats['by_status']['done']}, "
                          f"å¤±è´¥={source_stats['by_status']['failed']}")
                
            time.sleep(10)  # æ¯10ç§’æ£€æŸ¥ä¸€æ¬¡
            
        except Exception as e:
            print(f"âš ï¸ ç›‘æ§å¼‚å¸¸: {e}")
            time.sleep(5)
    
    print(f"â° è¾¾åˆ°æœ€å¤§ç­‰å¾…æ—¶é—´ ({max_wait_minutes} åˆ†é’Ÿ)")
    return False

def check_candidates(base_url="http://localhost:8000"):
    """æ£€æŸ¥å€™é€‰äººæ•°æ®"""
    print_step(4, "æ£€æŸ¥ç”Ÿæˆçš„å€™é€‰äººæ•°æ®")
    
    try:
        # è·å–å€™é€‰äººç»Ÿè®¡
        response = requests.get(f"{base_url}/dashboard/parsing", timeout=10)
        if response.status_code == 200:
            stats = response.json()['data']
            
            print(f"ğŸ“Š å€™é€‰äººç»Ÿè®¡:")
            print(f"   æ€»å€™é€‰äººæ•°: {stats['total_candidates']}")
            print(f"   æœ‰åŸæ–‡æ•°: {stats['candidates_with_texts']}")
            print(f"   å·²è§£ææ•°: {stats['parsed_candidates']}")
            print(f"   å¾…è§£ææ•°: {stats['pending_parse']}")
            
            if stats['total_candidates'] > 0:
                print(f"âœ… æˆåŠŸå‘ç° {stats['total_candidates']} ä¸ªå€™é€‰äºº")
                return True
            else:
                print(f"âš ï¸ æœªå‘ç°å€™é€‰äººï¼Œå¯èƒ½æ˜¯çˆ¬è™«è¿˜åœ¨è¿è¡Œæˆ–é‡åˆ°é—®é¢˜")
                return False
        else:
            print(f"âŒ è·å–å€™é€‰äººç»Ÿè®¡å¤±è´¥: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"âŒ æ£€æŸ¥å€™é€‰äººæ•°æ®å¼‚å¸¸: {e}")
        return False

def start_parsing(base_url="http://localhost:8000"):
    """å¯åŠ¨è§£æä»»åŠ¡"""
    print_step(5, "å¯åŠ¨æ™ºèƒ½è§£æä»»åŠ¡")
    
    try:
        config = {
            "batch_size": 5,
            "force_reparse": False
        }
        
        response = requests.post(
            f"{base_url}/parse/start",
            json=config,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"âœ… è§£æä»»åŠ¡å¯åŠ¨æˆåŠŸ")
            print(f"   å€™é€‰äººæ•°é‡: {result.get('candidates_count', 'N/A')}")
            print(f"   æ‰¹æ¬¡ID: {result.get('batch_id', 'N/A')}")
            return True
        else:
            print(f"âŒ è§£æä»»åŠ¡å¯åŠ¨å¤±è´¥: {response.status_code}")
            try:
                error_detail = response.json().get('detail', 'Unknown error')
                print(f"   é”™è¯¯è¯¦æƒ…: {error_detail}")
            except:
                pass
            return False
            
    except Exception as e:
        print(f"âŒ è§£æä»»åŠ¡å¯åŠ¨å¼‚å¸¸: {e}")
        return False

def check_field_coverage(base_url="http://localhost:8000"):
    """æ£€æŸ¥å­—æ®µè¦†ç›–ç‡"""
    print_step(6, "æ£€æŸ¥å­—æ®µè¦†ç›–ç‡ç»Ÿè®¡")
    
    try:
        response = requests.get(f"{base_url}/dashboard/coverage", timeout=10)
        if response.status_code == 200:
            stats = response.json()['data']
            
            print(f"ğŸ“Š å­—æ®µè¦†ç›–ç‡ç»Ÿè®¡:")
            print(f"   æ€»å€™é€‰äººæ•°: {stats['total_candidates']}")
            print(f"   åŸºç¡€è”ç³»è¦†ç›–: {stats['basic_contact_coverage']} ({stats['basic_contact_percentage']:.1f}%)")
            
            print(f"\nğŸ“‹ è¯¦ç»†è¦†ç›–ç‡:")
            coverage_fields = [
                ('email', 'é‚®ç®±'),
                ('homepage', 'ä¸»é¡µ'),
                ('github', 'GitHub'),
                ('institution', 'æœºæ„'),
                ('raw_text', 'åŸæ–‡')
            ]
            
            for field, name in coverage_fields:
                if field in stats['coverage_percentages']:
                    count = stats['coverage'][field]
                    percentage = stats['coverage_percentages'][field]
                    print(f"   {name}: {count} äºº ({percentage:.1f}%)")
            
            return True
            
    except Exception as e:
        print(f"âŒ æ£€æŸ¥å­—æ®µè¦†ç›–ç‡å¼‚å¸¸: {e}")
        return False

def show_final_summary(base_url="http://localhost:8000"):
    """æ˜¾ç¤ºæœ€ç»ˆæ€»ç»“"""
    print_step(7, "æœ€ç»ˆæ€»ç»“å’Œè®¿é—®æŒ‡å—")
    
    try:
        # è·å–å®Œæ•´ç»Ÿè®¡
        response = requests.get(f"{base_url}/dashboard/stats", timeout=10)
        if response.status_code == 200:
            stats = response.json()['data']
            
            print(f"ğŸ‰ æ¼”ç¤ºå®Œæˆ! ç³»ç»Ÿå·²å°±ç»ª")
            print(f"\nğŸ“ˆ ç³»ç»Ÿç»Ÿè®¡:")
            print(f"   å€™é€‰äººæ€»æ•°: {stats['parsing']['total_candidates']}")
            print(f"   è§£æè¿›åº¦: {stats['parsing']['parse_progress']:.1f}%")
            print(f"   ä»»åŠ¡æ€»æ•°: {stats['tasks']['total']['total']}")
            print(f"   åŸºç¡€ä¿¡æ¯è¦†ç›–: {stats['coverage']['basic_contact_percentage']:.1f}%")
            
            print(f"\nğŸŒ è®¿é—®é“¾æ¥:")
            print(f"   é¦–é¡µä»ªè¡¨ç›˜: {base_url}/")
            print(f"   å€™é€‰äººåˆ—è¡¨: {base_url}/candidates")
            print(f"   è§£æç®¡ç†: {base_url}/parse/review")
            print(f"   ç³»ç»Ÿæ—¥å¿—: {base_url}/logs")
            
            print(f"\nğŸ”§ APIç«¯ç‚¹:")
            print(f"   å®Œæ•´ç»Ÿè®¡: GET {base_url}/dashboard/stats")
            print(f"   å€™é€‰äººæ•°æ®: GET {base_url}/candidates")
            print(f"   å¯åŠ¨GitHubçˆ¬è™«: POST {base_url}/crawl/github/start")
            print(f"   å¯åŠ¨è§£æ: POST {base_url}/parse/start")
            
            return True
            
    except Exception as e:
        print(f"âŒ è·å–æœ€ç»ˆç»Ÿè®¡å¼‚å¸¸: {e}")
        return False

def main():
    """ä¸»æ¼”ç¤ºæµç¨‹"""
    print_header("Spidermind ç«¯åˆ°ç«¯æ¼”ç¤º")
    
    print("ğŸ¯ æœ¬æ¼”ç¤ºå°†å±•ç¤ºå®Œæ•´çš„çˆ¬è™«â†’è§£æâ†’å±•ç¤ºå·¥ä½œæµç¨‹")
    print("ğŸ“‹ æµç¨‹: æ’å…¥ä»»åŠ¡ â†’ è¿è¡Œçˆ¬è™« â†’ æ™ºèƒ½è§£æ â†’ æ•°æ®å±•ç¤º")
    
    base_url = "http://localhost:8000"
    
    # æ‰§è¡Œæ¼”ç¤ºæ­¥éª¤
    steps = [
        ("æ’å…¥æ¼”ç¤ºä»»åŠ¡", lambda: insert_demo_tasks()),
        ("æ£€æŸ¥æœåŠ¡å™¨", lambda: check_server_status(base_url)),
        ("å¯åŠ¨GitHubçˆ¬è™«", lambda: start_crawler("github", base_url=base_url)),
        ("å¯åŠ¨OpenReviewçˆ¬è™«", lambda: start_crawler("openreview", base_url=base_url)),
        ("å¯åŠ¨Homepageçˆ¬è™«", lambda: start_crawler("homepage", base_url=base_url)),
        ("ç›‘æ§çˆ¬è™«è¿›åº¦", lambda: monitor_crawl_progress(5, base_url)),
        ("æ£€æŸ¥å€™é€‰äººæ•°æ®", lambda: check_candidates(base_url)),
        ("å¯åŠ¨æ™ºèƒ½è§£æ", lambda: start_parsing(base_url)),
        ("æ£€æŸ¥å­—æ®µè¦†ç›–ç‡", lambda: check_field_coverage(base_url)),
        ("æ˜¾ç¤ºæœ€ç»ˆæ€»ç»“", lambda: show_final_summary(base_url))
    ]
    
    success_count = 0
    for i, (step_name, step_func) in enumerate(steps, 1):
        try:
            print(f"\nâ³ æ‰§è¡Œæ­¥éª¤ {i}: {step_name}")
            if step_func():
                success_count += 1
                print(f"âœ… æ­¥éª¤ {i} å®Œæˆ")
            else:
                print(f"âš ï¸ æ­¥éª¤ {i} é‡åˆ°é—®é¢˜ï¼Œä½†ç»§ç»­æ‰§è¡Œ")
        except Exception as e:
            print(f"âŒ æ­¥éª¤ {i} å¼‚å¸¸: {e}")
    
    print_header("æ¼”ç¤ºç»“æœ")
    print(f"ğŸ“Š æ‰§è¡Œç»“æœ: {success_count}/{len(steps)} æ­¥éª¤æˆåŠŸ")
    
    if success_count >= len(steps) * 0.7:  # 70%ä»¥ä¸ŠæˆåŠŸ
        print("ğŸ‰ æ¼”ç¤ºæˆåŠŸ! ç³»ç»Ÿè¿è¡Œæ­£å¸¸")
        print("\nğŸš€ ä¸‹ä¸€æ­¥å»ºè®®:")
        print("   1. æµè§ˆå™¨è®¿é—®ç³»ç»Ÿé¦–é¡µæŸ¥çœ‹æ•°æ®")
        print("   2. å°è¯•æ‰‹åŠ¨æ·»åŠ æ›´å¤šä»»åŠ¡")
        print("   3. æµ‹è¯•å€™é€‰äººä¿¡æ¯è¡¥å½•åŠŸèƒ½")
        print("   4. æŸ¥çœ‹å®æ—¶æ—¥å¿—å’Œç»Ÿè®¡ä¿¡æ¯")
    else:
        print("âš ï¸ æ¼”ç¤ºéƒ¨åˆ†æˆåŠŸï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        print("\nğŸ”§ æ•…éšœæ’é™¤å»ºè®®:")
        print("   1. ç¡®ä¿MySQLæ•°æ®åº“æ­£åœ¨è¿è¡Œ")
        print("   2. æ£€æŸ¥config/database.jsoné…ç½®")
        print("   3. ç¡®ä¿uvicornæœåŠ¡å™¨å·²å¯åŠ¨")
        print("   4. æŸ¥çœ‹app.logæ—¥å¿—æ–‡ä»¶")

if __name__ == "__main__":
    main()